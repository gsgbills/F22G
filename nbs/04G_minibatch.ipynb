{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "import pickle,gzip,math,os,time,shutil,torch,matplotlib as mpl,numpy as np,matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from torch import tensor,nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastcore.test import test_close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions(precision=2, linewidth=140, sci_mode=False, threshold=1000)\n",
    "torch.manual_seed(1)\n",
    "mpl.rcParams['image.cmap'] = 'gray'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open(Path('data')/'mnist.pkl.gz', 'rb') as f: \n",
    "    ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding='latin-1')\n",
    "x_train, y_train, x_valid, y_valid = map(tensor, [x_train, y_train, x_valid, y_valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 784, 10, 10000, 784)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n,m = x_train.shape\n",
    "c = y_train.max()+1\n",
    "nh = 50   # hidden\n",
    "v,w = x_valid.shape\n",
    "n,m,int(c), v, w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, n_in, nh, n_out):\n",
    "        super().__init__()\n",
    "        self.layers = [nn.Linear(n_in,nh), nn.ReLU(), nn.Linear(nh,n_out)]\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        for l in self.layers: x = l(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred shape: torch.Size([50000, 10])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.09, -0.21, -0.08,  0.10, -0.04,  0.08, -0.04, -0.03,  0.01,  0.06],\n",
       "        [-0.07, -0.14, -0.14, -0.03, -0.00,  0.13, -0.04,  0.03,  0.04,  0.14],\n",
       "        [-0.19, -0.04,  0.02,  0.21, -0.06, -0.00, -0.08, -0.01, -0.00,  0.02],\n",
       "        [-0.05, -0.21, -0.07,  0.08,  0.04,  0.08, -0.10, -0.01,  0.09,  0.01],\n",
       "        [-0.15, -0.19, -0.04,  0.06, -0.05,  0.15, -0.11,  0.01,  0.08,  0.05]], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model(m, nh, c)\n",
    "pred = model(x_train)\n",
    "print(\"Pred shape:\", pred.shape)\n",
    "pred[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Cross entropy loss\n",
    "Cross-entropy loss, also known as log loss or logistic loss, is a commonly used loss function in machine learning, especially for classification tasks. It measures the **difference between the predicted probability distribution of a model and the true probability distribution of the labels.**  \n",
    "A lower cross-entropy value indicates that the predicted probability distribution is closer to the true distribution, and thus the model's predictions are more accurate. A perfect model would have a cross-entropy loss of 0.\n",
    "The goal during the training of a classification model is to **minimize the cross-entropy loss**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will need to compute the softmax of our activations. This is defined by:\n",
    "$\\hbox{softmax(x)}_{i} = \\frac{e^{x_{i}}}{e^{x_{0}} + e^{x_{1}} + \\cdots + e^{x_{n-1}}}$\n",
    "<br>\n",
    "or more concisely:\n",
    "$\\hbox{softmax(x)}_{i} = \\frac{e^{x_{i}}}{\\sum\\limits_{0 \\leq j \\lt n} e^{x_{j}}}$\n",
    "<br>\n",
    "In practice, we will need the log of the softmax when we calculate the loss.\n",
    "<br>\n",
    "Below $e^{x_{i}} =$ `x.exp()`, and $ \\sum\\limits_{0 \\leq j \\lt n} e^{x_{j}}$ = `(x.exp().sum(-1,keepdim=True))`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the formula $\\log \\left ( \\frac{a}{b} \\right ) = \\log(a) - \\log(b)$\n",
    "gives a simplification when we compute the log softmax:<br>\n",
    "$log(a) =$ `x` ,     $log(b) =$ `x.exp().sum(-1,keepdim=True).log()`\n",
    "\n",
    "In cross-entropy, we don't want softmax, we want log of softmax:\n",
    "We want to keep that dimension `keepdim=True` so that when we do the divided by, \n",
    "we want a trailing unit axis (for the same reason as when we did our MSE loss function).\n",
    "A `sum()` with `keepdim=True` leaves a unit axis in that last position,\n",
    "so we don't have to put it back to avoid the broadcasting product issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.37, -2.49, -2.36,  ..., -2.31, -2.28, -2.22],\n",
      "        [-2.37, -2.44, -2.44,  ..., -2.27, -2.26, -2.16],\n",
      "        [-2.48, -2.33, -2.28,  ..., -2.30, -2.30, -2.27],\n",
      "        ...,\n",
      "        [-2.33, -2.52, -2.34,  ..., -2.31, -2.21, -2.16],\n",
      "        [-2.38, -2.38, -2.33,  ..., -2.29, -2.26, -2.17],\n",
      "        [-2.33, -2.55, -2.36,  ..., -2.29, -2.27, -2.16]], grad_fn=<SubBackward0>)\n"
     ]
    }
   ],
   "source": [
    "def log_softmax(x): return x - x.exp().sum(-1,keepdim=True).log()\n",
    "\n",
    "print(log_softmax(pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### LogSumExp trick\n",
    "**Problem:** Directly computing $\\sum_i e^{x_i}$ can lead to overflow and precision issues if the $x_i$ are large. Floating-point representation has lower precision for numbers far from zero, making derivative calculations unreliable, potentially resulting in zero derivatives when numbers are indistinguishable.\n",
    "\n",
    "**LogSumExp Trick:** To address this, we aim to compute $\\log(\\sum_i e^{x_i})$ in a numerically stable way.\n",
    "<br>\n",
    "Let $m = \\max(x_i)$. We want to avoid calculating $e^{x_i}$ directly.\n",
    "<br>\n",
    "Consider subtracting $m$ from each $x_i$ in the following sum:\n",
    "$\\sum_i e^{x_i} = e^{x_1} + e^{x_2} + \\dots + e^{x_n}$\n",
    "<br>\n",
    "Subtracting $m$ from each exponent changes the sum:\n",
    "$\\sum_i e^{x_i - m} = e^{x_1 - m} + e^{x_2 - m} + \\dots + e^{x_n - m}$\n",
    "<br>\n",
    "Using the exponent rule $e^{a - b} = \\frac{e^{a}}{e^{b}}$, \n",
    "we have $e^{x_i - m} = \\frac{e^{x_i}}{e^{m}} = e^{x_i} e^{-m}$.\n",
    "<br>\n",
    "Therefore:\n",
    "$\\sum_i e^{x_i - m} = e^{-m} e^{x_1} + e^{-m} e^{x_2} + \\dots + e^{-m} e^{x_n}$\n",
    "<br>\n",
    "Factoring out $e^{-m}$:\n",
    "$\\sum_i e^{x_i - m} = e^{-m} (e^{x_1} + e^{x_2} + \\dots + e^{x_n}) = e^{-m} \\sum_i e^{x_i}$\n",
    "<br>\n",
    "To recover the original sum, we multiply by $e^{m}$:\n",
    "$\\sum_i e^{x_i} = e^{m} \\sum_i e^{x_i - m}$\n",
    "<br>\n",
    "Taking the logarithm of both sides gives us the LogSumExp formula:\n",
    "$\\log(\\sum_i e^{x_i}) = \\log(e^{m} \\sum_i e^{x_i - m}) = \\log(e^{m}) + \\log(\\sum_i e^{x_i - m}) = m + \\log(\\sum_i e^{x_i - m})$\n",
    "\n",
    "By subtracting the maximum value $m$ from each $x_i$, we ensure that the largest exponent becomes 0, and all other exponents are negative or zero. This prevents overflow during the exponentiation and keeps the numbers within a more manageable range for floating-point arithmetic, leading to more stable derivative calculations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See above the output of `preds[:5]` to confirm the maxs of every row in the `preds`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.10, 0.14, 0.21,  ..., 0.14, 0.11, 0.14], grad_fn=<MaxBackward0>),\n",
       " torch.Size([50000]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ma = pred.max(-1)[0]\n",
    "ma, ma.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below using the LogSumExp trick, where: \n",
    "$ \\log \\left ( \\sum_{j=1}^{n} e^{x_{j}-a} \\right) $ = `x-a[:,None]).exp().sum(-1).log()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logsumexp(x):\n",
    "    a = x.max(-1)[0]  # a is as in the above formula, the max of the xj\n",
    "    return a + (x - a[:,None]).exp().sum(-1).log()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This way, we will avoid an overflow when taking the exponential of a big activation. <br>\n",
    "PyTorch implements this as `torch.logsumexp()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_close(logsumexp(pred), torch.logsumexp(pred, dim=-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now reimplement `log_softmax` using `logsumexp`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.37, -2.49, -2.36,  ..., -2.31, -2.28, -2.22],\n",
       "        [-2.37, -2.44, -2.44,  ..., -2.27, -2.26, -2.16],\n",
       "        [-2.48, -2.33, -2.28,  ..., -2.30, -2.30, -2.27],\n",
       "        ...,\n",
       "        [-2.33, -2.52, -2.34,  ..., -2.31, -2.21, -2.16],\n",
       "        [-2.38, -2.38, -2.33,  ..., -2.29, -2.26, -2.17],\n",
       "        [-2.33, -2.55, -2.36,  ..., -2.29, -2.27, -2.16]], grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def log_softmax(x): \n",
    "    return x - x.logsumexp(-1,keepdim=True)\n",
    "\n",
    "sm_pred = log_softmax(pred)\n",
    "sm_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Integer array indexing\n",
    "The cross entropy loss between a target $x$ and a prediction $p(x)$ is calculated as:\n",
    "$ -\\sum x\\, \\log p(x) $\n",
    "<br>\n",
    "However, since our targets $x$ are represented as integer indices $i$ (e.g., class labels), we can simplify the calculation. \n",
    "Instead of using the full formula, we can directly access the predicted probability of the target class using its index, i.e.,\n",
    "$-\\log(p_{i})$ where $i$ is the index of the desired target.\n",
    "<br>\n",
    "This can be done using NumPy-style [integer array indexing](https://docs.scipy.org/doc/numpy-1.13.0/reference/arrays.indexing.html#integer-array-indexing), which allows us to access specific elements in a tensor using their integer indices. \n",
    "In this case, we can use integer array indexing to directly access the predicted probability of the target class, making the calculation more efficient.\n",
    "<br>\n",
    "Rewritten formula: `loss = -log(predictions[target_index])`.\n",
    "Using integer array indexing simplifies the cross-entropy loss calculation and makes it more computationally efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 0, 4])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:3]  # the first 3 target labels are:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above are the first three label values in `y_train`: 5, 0, and 4.\n",
    "We want to find in our softmax predictions:\n",
    "the 5th prediction in the zeroth row, the 0th prediction in the first row, and the 4th prediction in the 2nd (index two) row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-2.20015025138855, -2.3723506927490234, -2.3550922870635986)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm_pred[0,5].item(),sm_pred[1,0].item(),sm_pred[2,4].item() # the (current) predictions for the first 3 targets are:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above values are what we add up for the first rows of our loss function. \n",
    "We use an \"index trick\" to do it all at once.\n",
    "We index using two lists: the first index is the (rows) list `[0, 1, 2]`, and the second index is `y_train[:3]`.\n",
    "So the indeces are going to be `[0,5]`, `[1,0]`, and `[2,4]`,  which is the same thing as above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2.20, -2.37, -2.36], grad_fn=<IndexBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm_pred[[0,1,2], y_train[:3]] # advanced indexing...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([50000, 10]), 50000, range(0, 50000))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm_pred.shape, sm_pred.shape[0], range(y_train.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, the '2 list indexing' gives us what we need for cross-entropy loss.\n",
    "We'll use `range(target.shape[0])` (i.e. range(50000)) as the first index,\n",
    "and y_train (the target labels) as the second index. \n",
    "Taking the negative `mean` of this gives us the cross-entropy loss."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def nll(input, target): \n",
    "    return -input[range(target.shape[0]), target].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nll(input, target):\n",
    "    \"\"\"\n",
    "    Calculate the negative log likelihood (NLL) loss.\n",
    "\n",
    "    Args:\n",
    "        input (Tensor): Predicted log probabilities. Shape: (batch_size, num_classes)\n",
    "        target (Tensor): True labels. Shape: (batch_size,)\n",
    "\n",
    "    Returns:\n",
    "        Tensor: NLL loss.\n",
    "    \"\"\"\n",
    "    assert isinstance(input, torch.Tensor) and input.ndim == 2, \"Input should be a 2D tensor\"\n",
    "    assert isinstance(target, torch.Tensor) and target.ndim == 1, \"Target should be a 1D tensor\"\n",
    "    assert input.shape[0] == target.shape[0], \"Input and target batch sizes should match\"\n",
    "    assert torch.all(target >= 0) and torch.all(target < input.shape[1]), \"Target labels should be within valid range\"\n",
    "\n",
    "    return -input[range(target.shape[0]), target].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch calls this negative log likelihood `nll` loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3003"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = nll(sm_pred, y_train) ; round(loss.item(),4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now with PyTorch's implementation, we compute the `nll_loss`,  passing it the result of the `log_softmax`, between the predictions `pred` and the actual labels `y_train`. The result is `Ptloss`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.300276517868042"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ptloss = F.nll_loss(F.log_softmax(pred, dim=-1), y_train); Ptloss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_close(Ptloss, loss, 1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In PyTorch, `F.log_softmax` and `F.nll_loss` are combined in one function, `F.cross_entropy`,\n",
    "lets check that it gives us the same thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_close(F.cross_entropy(pred, y_train), loss, 1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In above description, many confusing things go on. \n",
    "Lets look at each step, think what and why is doing it.\n",
    "Experiment with different values to see what's going on.\n",
    "\n",
    "**HW:** Reimplement `log_softmax(), nll_loss() and cross_entropy()` and compare them to PyTorch's values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Basic training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basically the training loop repeats over the following steps:\n",
    "- get the output of the model on a batch of inputs\n",
    "- compare the output to the labels we have and compute a loss\n",
    "- calculate the gradients of the loss with respect to every parameter of the model\n",
    "- update said parameters with those gradients to make them a little bit better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets create a training loop.\n",
    "The loss function is `F.cross_entropy`, the batch size `bs=64`. \n",
    "`xb` is the first minibatch, from 0 to 64 from the training set. \n",
    "The predictions `preds` are returned by calling the `model(xb)`, and the result shape is `[64,10]`, \n",
    "i.e., for each image in the minibatch we have 10 probabilities, one for each digit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 10])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_func = F.cross_entropy\n",
    "\n",
    "bs=64                 # batch size\n",
    "xb = x_train[0:bs]     # a mini-batch from x of size bs\n",
    "preds = model(xb)      # predictions for this mini-batch\n",
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.09, -0.21, -0.08,  0.10, -0.04,  0.08, -0.04, -0.03,  0.01,  0.06], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[0]   # predictions for first image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `yb`s are the first 64 target values, i.e., the actual digits. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64]),\n",
       " tensor([5, 0, 4, 1, 9, 2, 1, 3, 1, 4, 3, 5, 3, 6, 1, 7, 2, 8, 6, 9, 4, 0, 9, 1, 1, 2, 4, 3, 2, 7, 3, 8, 6, 9, 0, 5, 6, 0, 7, 6, 1, 8, 7, 9,\n",
       "         3, 9, 8, 5, 9, 3, 3, 0, 7, 4, 9, 8, 0, 9, 4, 1, 4, 4, 6, 0]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yb = y_train[0:bs] # the corresponding (true) targets\n",
    "yb.shape, yb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start with a bad loss, because on the first batch step the weights are random.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.30, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_func(preds, yb)   #, loss_func(preds, yb).item() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What did we predict? \n",
    "For each one of the 64 rows (each one is an input image), we have to go get the highest prediction number,\n",
    "i.e., we've to find the **index of the highest number**, and for this we use [`argmax()`](https://docs.pytorch.org/docs/stable/generated/torch.argmax.html).   Below are the current predictions for the 64 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 9, 3, 8, 5, 9, 3, 9, 3, 9, 5, 3, 9, 9, 3, 9, 9, 5, 8, 7, 9, 5, 3, 8, 9, 5, 9, 5, 5, 9, 3, 5, 9, 7, 5, 7, 9, 9, 3, 9, 3, 5, 3, 8,\n",
       "        3, 5, 9, 5, 9, 5, 3, 9, 3, 8, 9, 5, 9, 5, 9, 5, 8, 8, 9, 8])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.argmax(dim=1) # take the argmax on the column 1 same as torch.argmax(preds, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets calculate `accuracy` as a metric for understanding progress. \n",
    "It compares the predictions `out.argmax` to the actuals `yb`, and returns a bunch of booleans. \n",
    "We turn those into floats (1.0s and 0.0s) and the `mean` of those floats is the accuracy. \n",
    "The current accuracy, as expected, is ~ 10%, because we havent trained yet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def accuracy(out, yb): \n",
    "    assert len(out) == len(yb), \"Number of predictions and targets must match\"\n",
    "    return (out.argmax(dim=1)==yb).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09375"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(preds, yb).item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train lets set a learning rate `lr` and do a few (3) `epochs`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.5   # learning rate\n",
    "epochs = 3 # how many epochs to train for"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets define a `report` function to print the `loss` and `accuracy`.\n",
    "below (`:.3f`) is a format specifier of Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def report(loss, preds, yb): print(f'{loss:.3f}, {accuracy(preds, yb):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss  Accuracy\n",
      "2.304, 0.094\n"
     ]
    }
   ],
   "source": [
    "xb,yb = x_train[:bs],y_train[:bs]    #input and target batches\n",
    "preds = model(xb)\n",
    "print('Loss  Accuracy')\n",
    "report(loss_func(preds, yb), preds, yb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each `epoch` we loop with `i` through the `n` (the 50,000 training rows), skipping by 64, the batch size, each time.\n",
    "We create a slice `s` that starts at `i`, e.g., 0, and goes up to  64,\n",
    "unless we've gone past the end, in which case we'll just go up to `n`. \n",
    "We slice `s` into our training set for the `xb` and `yb` batches.  \n",
    "We call the `model` to calculate the predictions `preds`, then call our `loss_func` function, and do the `loss.backward()`.\n",
    "Then, with `torch.no_grad()`, we go through each layer `l` in `model.layers`.\n",
    "If the layer `l` has `weight`, we update the `l.weight` to current weights minus the gradients `l.weights.grad` times `lr`.\n",
    "We also update the `l.bias` to current bias minus the gradients `l.bias.grad * lr`.\n",
    "And then zero out the gradients of the weights and biases with `.grad_zero_()`.\n",
    "The last `_` means do it in place. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss  Accuracy\n",
      "0.191, 0.938\n",
      "0.047, 1.000\n",
      "0.032, 1.000\n"
     ]
    }
   ],
   "source": [
    "print('Loss  Accuracy')\n",
    "for epoch in range(epochs):\n",
    "    for i in range(0, n, bs):\n",
    "        s = slice(i, min(n,i+bs))\n",
    "        xb,yb = x_train[s],y_train[s]\n",
    "        preds = model(xb)\n",
    "        loss = loss_func(preds, yb)\n",
    "        loss.backward()\n",
    "        with torch.no_grad():\n",
    "            for l in model.layers:\n",
    "                if hasattr(l, 'weight'):\n",
    "                    l.weight -= l.weight.grad * lr\n",
    "                    l.bias   -= l.bias.grad   * lr\n",
    "                    l.weight.grad.zero_()\n",
    "                    l.bias.grad.zero_()\n",
    "    report(loss, preds, yb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our accuracy on  the training set, only three epochs,...\n",
    "We now have a handwritten digit recognizer that trains quickly.\n",
    "Later we're going to refactor this training loop to make it simpler.\n",
    "Then we're going to add a validation set to it and a multi-processing data loader.\n",
    "Then we'll be in a good position to start training some more interesting models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HW: TODO: recreate matrix  multiply, forward and backward passes, something that steps through layers.\n",
    "Recreate the idea of `.forward` and `.backward`.  \n",
    "Make sure to fully understand what's going on. \n",
    "First pick a smaller part of that, the most interesting part, \n",
    "or just go through and look really closely at these notebooks. \n",
    "Restart the notebook kernel and clear output, try to think what are the shapes and values of the variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Using parameters and optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Parameters\n",
    "PyTorch's torch.nn has the `nn.Module` class. \n",
    "(We don't normally use it this way, here just to see how it works.) \n",
    "We create an instance `m1` of Module and can assign things to its attributes, e.g.,\n",
    "assign a linear layer to a new attribute `foo`. \n",
    "We print `m1` and it is a  module containing `foo`, a linear layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Module(\n",
       "  (foo): Linear(in_features=3, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1 = nn.Module()\n",
    "m1.foo = nn.Linear(3,4)\n",
    "m1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To show all of the named children of that module, if\n",
    "we just call `m1.named_children()`, it just prints out the generator object, not helpful. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.named_children at 0x120f30660>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1.named_children()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A generator will only produce contents when we \"do something\" with it, e.g., list them out.\n",
    "So a list around a generator is one way to run the generator and get its output. \n",
    "There's one child `foo` and it's a linear layer.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('foo', Linear(in_features=3, out_features=4, bias=True))]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(m1.named_children())   #trick to look inside generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see all of the `parameters` of the `m1` module:\n",
    "There are two `parameters`: a 4x3 tensor (for the weights), and a 4 long vector (for the biases).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 0.57,  0.43, -0.30],\n",
       "         [ 0.13, -0.32, -0.24],\n",
       "         [ 0.51,  0.04,  0.22],\n",
       "         [ 0.13, -0.17, -0.24]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.01, -0.51, -0.39,  0.56], requires_grad=True)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(m1.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could use `__call__`,  but it is better to refactor using `forward` \n",
    "such that it would automatically do what is necessary to make all the automatic gradients.\n",
    "`forward` defines the forward pass through the network.\n",
    "When we call an instance of a module (e.g., module(input)), PyTorch's __call__ method will internally call our forward method.\n",
    "We should override forward to implement our module's logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, n_in, nh, n_out):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(n_in,nh)\n",
    "        self.l2 = nn.Linear(nh,n_out)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x): return self.l2(self.relu(self.l1(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`MLP` above is an  example of creating a custom PyTorch Module, that knows what are all the attributes\n",
    "we added to it and what are all the parameters. \n",
    "`nn.Module` provides: automatic parameter management, GPU support, built-in hooks, easy model saving/loading, and integration with PyTorch components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (l1): Linear(in_features=784, out_features=50, bias=True)\n",
       "  (l2): Linear(in_features=50, out_features=10, bias=True)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MLP(m, nh, c)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1: Linear(in_features=784, out_features=50, bias=True)\n",
      "l2: Linear(in_features=50, out_features=10, bias=True)\n",
      "relu: ReLU()\n"
     ]
    }
   ],
   "source": [
    "for name,l in model.named_children(): print(f\"{name}: {l}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can go through the `model.parameters` and print out their shapes:\n",
    "`l1` weights, `l1` biases, `l2` weights and biases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 784])\n",
      "torch.Size([50])\n",
      "torch.Size([10, 50])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for p in model.parameters(): print(p.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With nn.Module, parameter management becomes effortless. You can:\n",
    "Define layers as attributes, and they'll automatically be registered as parameters.\n",
    "Iterate over parameters with model.parameters() and update them using a simple loop: `for p in model.parameters(): p -= p.grad * lr`\n",
    "Zero out gradients with `model.zero_grad()`.\n",
    "This simplifies the code and makes it more flexible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit():\n",
    "    for epoch in range(epochs):\n",
    "        for i in range(0, n, bs):\n",
    "            s = slice(i, min(n,i+bs))\n",
    "            xb,yb = x_train[s],y_train[s]\n",
    "            preds = model(xb)\n",
    "            loss = loss_func(preds, yb)\n",
    "            loss.backward()\n",
    "            with torch.no_grad():\n",
    "                for p in model.parameters(): p -= p.grad * lr\n",
    "                model.zero_grad()\n",
    "        report(loss, preds, yb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets call `report()` on the model predictions before calling `fit()`: the accuracy is ~ 10%, and the loss is high."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss  Accuracy\n",
      "0.032, 0.047\n"
     ]
    }
   ],
   "source": [
    "xc,yc = x_train[:bs],y_train[:bs]\n",
    "preds = model(xc)\n",
    "print('Loss  Accuracy')\n",
    "report(loss, preds, yc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running `fit()` the accuracy goes up and the loss goes down.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.408, 0.938\n",
      "0.098, 1.000\n",
      "0.048, 1.000\n"
     ]
    }
   ],
   "source": [
    "fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch's nn.Module automatically registers submodules as parameters by overriding `__setattr__`. This means when you define layers as attributes, they're properly tracked as model parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create `MyModule` to mimic `nn.Module.` It will:\n",
    "*    Store layers in a dictionary in __init__.\n",
    "*    Override `__setattr__` to automatically register layers in the dictionary when set as attributes.\n",
    "*    Implement `__repr__` to return a string representation of the modules.\n",
    "*    Define parameters as a generator that yields parameters from each layer, creating an iterator.\n",
    "\n",
    "`__setattr__` gets passed the name of the attribute, the key, and the value is the right hand side of the equal sign.  \n",
    "Names that start with an `_` are used for private stuff, so we check that it doesn't.\n",
    "It will put the value `v` into the modules dictionary with `k` key.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModule:\n",
    "    def __init__(self, n_in, nh, n_out):\n",
    "        self._modules = {}  # dictionary for all the layers\n",
    "        self.l1 = nn.Linear(n_in,nh) \n",
    "        self.l2 = nn.Linear(nh,n_out)\n",
    "        \n",
    "    def __setattr__(self,k,v): #automatically called every time an attribute is set.\n",
    "        if not k.startswith(\"_\"): self._modules[k] = v # _ is for private stuff\n",
    "        super().__setattr__(k,v) # call the python setattr\n",
    "        \n",
    "    def __repr__(self): return f'{self._modules}' # returns the _modules dictionary\n",
    "    \n",
    "    def parameters(self):\n",
    "        for l in self._modules.values():\n",
    "            yield from l.parameters()    # equivalent to above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below comes from `__repr__`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'l1': Linear(in_features=784, out_features=50, bias=True), 'l2': Linear(in_features=50, out_features=10, bias=True)}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl = MyModule(m,nh,10)\n",
    "mdl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can create one of these modules and if we loop through its parameters, they are printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 784])\n",
      "torch.Size([50])\n",
      "torch.Size([10, 50])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for p in mdl.parameters(): print(p.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Registering modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the original `layers` approach, but we have to register the modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [nn.Linear(m,nh), nn.ReLU(), nn.Linear(nh,c)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### nn.ModuleList\n",
    "\n",
    "Instead of manually storing and registering modules with `add_module()`, we can use PyTorch's ModuleList. \n",
    "This container holds submodules like a regular list, but also registers them properly for training, saving, and loading. \n",
    "We simply pass a list of layers to ModuleList.\n",
    "\n",
    "Lets define `SequentialModel` as a Module like `nn.Sequential`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequentialModel(nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        for l in self.layers: x = l(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "We create a `model` passing in the `layers`.\n",
    "Below output shows `model` containing the `ModuleList` with my layers. \n",
    "`nn.ModuleList` does this for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequentialModel(\n",
       "  (layers): ModuleList(\n",
       "    (0): Linear(in_features=784, out_features=50, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=50, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SequentialModel(layers)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets call `fit()` to check that it still works with the new `model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.172, 0.938\n",
      "0.110, 1.000\n",
      "0.032, 1.000\n"
     ]
    }
   ],
   "source": [
    "fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Reduce - An alternative way to invoke all the layers\n",
    "`functools.reduce()` is a function that applies a binary function cumulatively to the items of an iterable, reducing the iterable to a single value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below \n",
    "```python\n",
    "return reduce(lambda val,layer: layer(val), self.layers, x)\n",
    "```\n",
    "is the same as: \n",
    "```python\n",
    "for l in self.layers: x = l(x)  return x\n",
    "```\n",
    "`Reduce` implements the *reduction concept*, <u>iteratively combining a sequence into a single value.</u>\n",
    "If a third parameter (`initial_value`, e.g., `x`) is given, the process starts with it.\n",
    "`Reduce` then iterates through a sequence (e.g., `self.layers`). \n",
    "For each element (`layer`), it applies a function (e.g., a `lambda`).\n",
    "This function receives the accumulated result (initially `x`) and the current `layer`. \n",
    "The function's output becomes the new accumulated result for the next iteration.\n",
    "So, the function is called with (`x`, first `layer`), then with (`result_1`, second `layer`), and so on.\n",
    "Although the iteration is internal, `reduce` effectively loops through the sequence, applying the function to the accumulated result and each element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        super().__init__()\n",
    "        self.layers = layers\n",
    "        for i,l in enumerate(self.layers): self.add_module(f'layer_{i}', l)\n",
    "        \n",
    "    def forward(self, x): return reduce(lambda val,layer: layer(val), self.layers, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (layer_0): Linear(in_features=784, out_features=50, bias=True)\n",
       "  (layer_1): ReLU()\n",
       "  (layer_2): Linear(in_features=50, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model(layers)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Shape: torch.Size([16, 10])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[     0.04,    -10.43,      0.94,      4.10,     -0.83,     -0.49,    -10.69,      2.21,      2.04,     10.81],\n",
       "        [    -2.54,      2.22,      1.49,      8.90,     -5.05,      2.80,     -1.45,     -2.52,      0.04,     -2.12],\n",
       "        [    -5.49,      0.37,      2.46,      6.52,     -7.43,     -4.82,    -12.32,     16.02,      1.54,      5.50],\n",
       "        [     6.49,     -5.62,      1.47,      3.37,     -3.81,     -0.21,      1.11,     -0.29,      1.10,     -1.08],\n",
       "        [    -0.73,     -9.27,     -3.98,      1.98,      0.55,      2.33,     -4.50,      3.13,      0.24,     10.43],\n",
       "        [    13.63,     -5.06,      0.87,     -5.27,      1.05,     -4.54,      8.77,     -3.96,     -4.18,      3.93],\n",
       "        [     2.00,     -9.79,      0.90,      5.80,     -7.26,      5.17,     -6.13,     -4.00,     11.52,      2.41],\n",
       "        [    -3.28,      1.84,     -2.85,     11.18,    -10.29,     16.43,      2.35,     -3.96,     -2.00,     -3.46],\n",
       "        [    -0.32,     -9.99,     -6.51,      2.10,     -3.59,     12.93,      2.51,     -2.61,      1.04,      2.51],\n",
       "        [     4.39,     -4.31,      8.58,      4.49,     -6.85,     -1.29,      0.51,      2.12,      1.18,     -5.41],\n",
       "        [    -1.59,     -3.46,      0.83,     -4.14,     11.32,     -1.31,     -2.40,      1.51,     -3.56,      2.29],\n",
       "        [     0.59,     -0.29,     -1.19,      2.71,     -6.65,      8.55,      1.61,     -1.88,      1.23,     -1.38],\n",
       "        [    10.14,     -0.88,      2.69,     -1.04,     -6.84,      2.56,     -0.11,      2.06,     -2.46,     -1.92],\n",
       "        [     0.56,     -3.59,      0.06,      1.26,     -2.20,      0.79,     -0.56,     -2.76,      8.89,     -1.45],\n",
       "        [     0.85,     -2.77,      0.50,     -3.88,      5.94,     -0.98,     -0.47,     -0.16,     -0.88,      2.04],\n",
       "        [    -0.08,     -1.71,     -1.52,      0.01,     -1.86,     -0.11,     -1.83,     -0.86,      8.31,      1.50]],\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Model Shape:\", model(xb).shape)\n",
    "\n",
    "model(xb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### nn.Sequential\n",
    "We implemented `Sequential`, so we can use PyTorch's `nn.Sequential`. \n",
    "We can pass in our layers and we can fit, and see the model (very  similar to the one we built).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.186, 0.938\n",
      "0.137, 0.938\n",
      "0.119, 1.000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(0.01, grad_fn=<NllLossBackward0>), tensor(1.))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = nn.Sequential(nn.Linear(m,nh), nn.ReLU(), nn.Linear(nh,10))\n",
    "\n",
    "model(xb)\n",
    "\n",
    "fit()\n",
    "loss_func(model(xb), yb), accuracy(model(xb), yb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer\n",
    "Looping through model parameters, updating them using their gradients and a learning rate, and then resetting their gradients to zero is a common pattern in training — this is the role of an **optimizer**.\n",
    "<br>\n",
    "We’ll define our own `Optimizer` class to handle this. \n",
    "In the `__init__` method, we pass in: `params`: the parameters we want to optimize, `lr`: the learning rate.\n",
    "Since `params` could be a generator, we convert it to a list using `list(params)` to ensure we can iterate over it multiple times.\n",
    "The `step` method loops through each parameter and updates its value using the gradient and learning rate.\n",
    "The `zero_grad` method loops through each parameter and sets its `.grad` to zero, preparing for the next backward pass.\n",
    "<br>\n",
    "**Note:** If we access or modify `.data` directly (e.g. `param.data -= lr * param.grad`), we bypass PyTorch’s computation graph. \n",
    "This is a shortcut that avoids wrapping the operation in a `torch.no_grad()` block — but use it with care."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "class Optimizer():\n",
    "    def __init__(self, params, lr=0.5): self.params,self.lr=list(params),lr\n",
    "        \n",
    "    def step(self):\n",
    "        with torch.no_grad():\n",
    "            for p in self.params: p -= p.grad * self.lr\n",
    "\n",
    "    def zero_grad(self):\n",
    "        for p in self.params: p.grad.data.zero_(). # .data is old idiom in Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizer:\n",
    "    def __init__(self, params, lr=0.5):\n",
    "        self.params = list(params)  # Ensure it's a list\n",
    "        self.lr = lr\n",
    "\n",
    "    def step(self):\n",
    "        with torch.no_grad():\n",
    "            for p in self.params:\n",
    "                if p.grad is not None: p -= self.lr * p.grad\n",
    "\n",
    "    def zero_grad(self):\n",
    "        for p in self.params:\n",
    "            if p.grad is not None: p.grad.zero_()   #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Linear(m,nh), nn.ReLU(), nn.Linear(nh,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create our optimizer `opt`, pass it in the `model.parameters()`, which have been automatically constructed by `nn.Sequential` as a `nn.Module`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Optimizer(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the new loop we call `opt.step()`, and `opt.zero_grad()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.159, 0.938\n",
      "0.152, 0.938\n",
      "0.077, 1.000\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    for i in range(0, n, bs):\n",
    "        s = slice(i, min(n,i+bs))\n",
    "        xb,yb = x_train[s],y_train[s]\n",
    "        preds = model(xb)\n",
    "        loss = loss_func(preds, yb)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "    report(loss, preds, yb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've now built our own [SGD](https://en.wikipedia.org/wiki/Stochastic_gradient_descent) optimizer from scratch. PyTorch provides this functionality in [`optim.SGD`](https://docs.pytorch.org/docs/stable/generated/torch.optim.SGD.html) (it also handles stuff like momentum, which we'll look at later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define `get_model()` to return *both* the sequential model and the optimizer for it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = nn.Sequential(nn.Linear(m,nh), nn.ReLU(), nn.Linear(nh,10))\n",
    "    return model, optim.SGD(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After asigning `model, opt = get_model()`, we can call `loss_func` to see where it's starting.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting loss value: 2.321\n"
     ]
    }
   ],
   "source": [
    "model,opt = get_model()\n",
    "sloss = loss_func(model(xb), yb).item()\n",
    "print(\"Starting loss value:\", f\"{sloss:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we write the training loop again, same as before but with the `optim.SGD' optimizer: \n",
    "Go through each `epoch`, go through each starting point for the batches, grab the slice,\n",
    "slice into our X and Y in the training set, calculate predictions `preds`, calculate the `loss`,\n",
    "do the `backward` pass, do the optimizer step `opt`, do the zero gradient and print out loss and accuracy at the end of each epoch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss accuracy\n",
      "0.227, 0.938\n",
      "0.129, 1.000\n",
      "0.138, 1.000\n"
     ]
    }
   ],
   "source": [
    "print (\"loss accuracy\")\n",
    "for epoch in range(epochs):\n",
    "    for i in range(0, n, bs):\n",
    "        s = slice(i, min(n,i+bs))\n",
    "        xb,yb = x_train[s],y_train[s]\n",
    "        preds = model(xb)\n",
    "        loss = loss_func(preds, yb)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "    report(loss, preds, yb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "It's clunky to iterate through minibatches of x and y values separately:\n",
    "```python\n",
    "    xb = x_train[s]\n",
    "    yb = y_train[s]\n",
    "```\n",
    "Instead, let's do these two steps together, by introducing a `Dataset` class:\n",
    "```python\n",
    "    xb,yb = train_ds[s]\n",
    "```\n",
    "Our Dataset class takes in independent and dependent variables, stored as self.x and self.y. It implements two key methods:\n",
    "*    `__len__`: returns the number of samples (length of self.x) for use with len().\n",
    "*   `__getitem__`: returns a tuple of corresponding x and y values for a given index, enabling indexing like `xb, yb = train_ds[i]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class Dataset():\n",
    "    def __init__(self, x, y): self.x,self.y = x,y\n",
    "    def __len__(self): return len(self.x)\n",
    "    def __getitem__(self, i): return self.x[i],self.y[i]  # For square brackets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a Dataset `train_ds` containing the `x_train` and `y_train`,\n",
    "and another Dataset `valid_ds` containing the `x_valid` and `y_valid`.\n",
    "Let's check the length of those datasets is the same as the length of the x’s and they are. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds,valid_ds = Dataset(x_train, y_train),Dataset(x_valid, y_valid)\n",
    "assert len(train_ds)==len(x_train)\n",
    "assert len(valid_ds)==len(x_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can say `xb, yb =train_ds[0:5]` to pass in a slice.\n",
    "We check that the shapes are correct, and print the x`s and y's.\n",
    "We've created a Dataset from  scratch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
       " tensor([5, 0, 4, 1, 9]))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb,yb = train_ds[0:5]\n",
    "assert xb.shape==(5,28*28)\n",
    "assert yb.shape==(5,)\n",
    "xb,yb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We call get_model(), and the loop now uses the dataset: ` xb,yb = train_ds[i:min(n,i+bs)]`. It still runs ok. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss accuracy\n",
      "0.267, 0.938\n",
      "0.113, 1.000\n",
      "0.146, 1.000\n"
     ]
    }
   ],
   "source": [
    "model,opt = get_model()\n",
    "print(\"loss accuracy\")\n",
    "for epoch in range(epochs):\n",
    "    for i in range(0, n, bs):\n",
    "        xb,yb = train_ds[i:min(n,i+bs)]\n",
    "        preds = model(xb)\n",
    "        loss = loss_func(preds, yb)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "    report(loss, preds, yb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previously, our loop iterated over batches (xb, yb) like this:\n",
    "```python\n",
    "for i in range(0, n, bs):\n",
    "    xb,yb = train_ds[i:min(n,i+bs)]\n",
    "    ...\n",
    "```\n",
    "Let's make our loop much cleaner, using a dataloader:\n",
    "\n",
    "```python\n",
    "for xb,yb in train_dl:\n",
    "    ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `DataLoader` is an **iterator** that yields batches of data from a Dataset, with a specified batch size `bs`. In a for loop, it sequentially returns batches, enabling efficient iteration over the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader():\n",
    "    def __init__(self, ds, bs): self.ds,self.bs = ds,bs\n",
    "    def __iter__(self):\n",
    "        for i in range(0, len(self.ds), self.bs): \n",
    "            yield self.ds[i:i+self.bs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create a `train_dl` and `valid_dl` `DataLoader`s from the train and valid Dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, bs)\n",
    "valid_dl = DataLoader(valid_ds, bs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get one thing out of an iterator, `iter` will also call `__iter__`, \n",
    "and `next` will grab just one value from it. \n",
    "We run it and confirm `xb` is a 64 by 784."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 784])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb,yb = next(iter(valid_dl))\n",
    "xb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check what it looks like, let's grab the first element of our X batch, make it 28 by 28.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(xb[0].view(28,28))\n",
    "yb[0].item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we simplify the `fit` function to just loop `for xb,yb in train_dl`. \n",
    "And it still works  the same way. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "model,opt = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit():\n",
    "    for epoch in range(epochs):\n",
    "        for xb,yb in train_dl:\n",
    "            preds = model(xb)\n",
    "            loss = loss_func(preds, yb)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "        report(loss, preds, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.321, 0.938\n",
      "0.215, 0.938\n",
      "0.183, 0.938\n"
     ]
    }
   ],
   "source": [
    "fit()\n",
    "#loss_func(model(xb), yb).item(), accuracy(model(xb), yb).item()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random sampling\n",
    "For better training, our dataset should be processed in a randomized order each epoch. The `Sampler` class handles this: it iterates through indices 0 to n, either sequentially (default) or randomly shuffled (`shuffle=True`).\n",
    "But the validation set shouldn't be randomized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampler():\n",
    "    def __init__(self, ds, shuffle=False): \n",
    "        self.n,self.shuffle = len(ds),shuffle\n",
    "    def __iter__(self):\n",
    "        res = list(range(self.n))\n",
    "        if self.shuffle: random.shuffle(res)\n",
    "        return iter(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below `sws` is a sampler **without** shuffle. \n",
    "We make an iterator `it` from `sws` and print a few things, it's just printing out the indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "sws = Sampler(train_ds)\n",
    "\n",
    "it = iter(sws)\n",
    "for o in range(5): print(next(it))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we can do the same thing using islice, to grab the first five things from a sampler when it's not shuffled, just indexes.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import islice\n",
    "\n",
    "list(islice(sws, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we add `shuffle=True`, it calls `random.shuffle()`, which (pseudo-)randomly permuts them. \n",
    "Below we've got 5 (pseudo)random indexes of the source data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[26895, 24627, 6693, 9828, 28677]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss = Sampler(train_ds, shuffle=True)\n",
    "list(islice(ss, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why is this useful? We define `BatchSampler` to perform batching using islice. It accepts a `sampler` (index generator) and a batch_size (`bs`), and then yields iterators of index batches with size `bs`.\n",
    "<br>\n",
    "We put Fastcore's `fc.store_attr()` in `__init__`, as a one line of code to store all the attributes.\n",
    "`fc.chunked(it, chunk_sz=None, drop_last=False, n_chunks=None)`\n",
    "return batches from iterator `it` of size `chunk_sz` (or return `n_chunks` total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastcore.all as fc\n",
    "\n",
    "class BatchSampler():\n",
    "    def __init__(self, sampler, bs, drop_last=False): fc.store_attr()\n",
    "\n",
    "    def __iter__(self): yield from fc.chunked(iter(self.sampler), self.bs, drop_last=self.drop_last)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `BatchSampler`, we can group indices from the Sampler `ss` into batches of 4. \n",
    "Each iteration will then output a sequence of four indices, enabling batch processing of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[15838, 6279, 33799, 12615],\n",
       " [40574, 1937, 14529, 49351],\n",
       " [14232, 32528, 38729, 48034],\n",
       " [46686, 14959, 13852, 29468],\n",
       " [8767, 34273, 25075, 12773]]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batchs = BatchSampler(ss, 4)\n",
    "list(islice(batchs, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`collate(b)` takes a batch `b` of data points, where each data point is a tuple (x, y).\n",
    "`xs, yz = zip(*b)` \"unzips\" the batch, grouping the x values together and the y values together into tuples `xs` and `ys`.\n",
    "`torch.stack()` converts the tuples into PyTorch tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate(b):\n",
    "    xs,ys = zip(*b)\n",
    "    return torch.stack(xs),torch.stack(ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the `train_ds` to create a `t_samp` sampler, and then go through each thing in it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_samp = BatchSampler(Sampler(train_ds, shuffle=False), bs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's grab one output thing `o` from `t_samp` the BatchSampler. \n",
    "`o` contains `bs` (64) indeces in order. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o = next(iter(t_samp))\n",
    "len(o), o[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we did a training sampler, `t2_samp` with `shuffle=True` that order would be randomized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, [11224, 46164, 3986, 7288, 49889, 32859, 47806, 48259, 36943, 37375])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2_samp = BatchSampler(Sampler(train_ds, shuffle=True), bs)\n",
    "o2 = next(iter(t2_samp))\n",
    "len(o2), o2[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What did the BatchSampler produced? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the output of the BatchSampler is a {<class 'list'>} of length 64 of <class 'int'>\n"
     ]
    }
   ],
   "source": [
    "print(f\"the output of the BatchSampler is a\", {type(o)}, f\"of length {len(o)} of\", type(o[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new Dataloader does\n",
    "```python\n",
    "def __iter__(self): \n",
    "    yield from (self.collate_fn(self.ds[i] for i in b) for b in self.batchs)\n",
    "```\n",
    "Lets explore what is `self.ds[i] for i in b`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(list, 64, tuple)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = [train_ds[i] for i in o]\n",
    "type(p), len(p), type(p[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`p[0]` is a tuple. \n",
    "It's got  the `x` (image) and the `y` (independent variable), which is not what we want. \n",
    "What we want is something that we can loop through. We want to get batches. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(5), 784)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p[0][1], len(p[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `collate` function combines batches of x and y values into two tensors. \n",
    "It uses Python's `zip()` function to transpose the data, grouping x values together and y values together. \n",
    "Specifically, `xs, ys = zip(*batch)` aggregates the values, which are then stacked to form tensors for the batch.\n",
    "`zip()` aggregates elements from multiple iterables, making it useful for tasks like creating dictionaries or, in this case, collating data for batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs,ys = zip(*p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 0, 4, 1, 9, 2, 1, 3, 1, 4, 3, 5, 3, 6, 1, 7, 2, 8, 6, 9, 4, 0, 9, 1, 1, 2, 4, 3, 2, 7, 3, 8, 6, 9, 0, 5, 6, 0, 7, 6, 1, 8, 7, 9,\n",
       "        3, 9, 8, 5, 9, 3, 3, 0, 7, 4, 9, 8, 0, 9, 4, 1, 4, 4, 6, 0])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack(ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We modify the `DataLoader` to use a `BatchSampler`, which provides indices for each batch. \n",
    "The `DataLoader` then retrieves the corresponding dataset items for each index, resulting in a list. \n",
    "Finally, the collate function is used to combine the x and y values into tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Todo HW Experiment with these to see what everything is taking in\n",
    "class DataLoader():\n",
    "    def __init__(self, ds, batchs, collate_fn=collate): fc.store_attr()\n",
    "    def __iter__(self): yield from (self.collate_fn(self.ds[i] for i in b) for b in self.batchs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create a training/validation sampler, `train_samp`/`valid_samp` \n",
    "which is a batch sampler over the training/validation set with `shuffle=True/False.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samp = BatchSampler(Sampler(train_ds, shuffle=True ), bs)\n",
    "valid_samp = BatchSampler(Sampler(valid_ds, shuffle=False), bs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can pass those samplers (`train_samp` and `valid_samp`) into the `DataLoader` class, to create `train_dl` and `valid_dl`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, batchs=train_samp)\n",
    "valid_dl = DataLoader(valid_ds, batchs=valid_samp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do as before `xb, yb, next, iter`, and this time we use `valid_dl`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xb,yb = next(iter(valid_dl))\n",
    "plt.imshow(xb[0].view(28,28))\n",
    "yb[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We just check the shapes. \n",
    "This is how PyTorch's DataLoader works, all the pieces they have. \n",
    "They have  samplers, batch samplers, a collation function and  DataLoaders. <br>\n",
    "Homework: Experiment with these carefully to see what each thing's taking in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 784]), torch.Size([64]))"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb.shape,yb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.200, 0.875\n",
      "0.165, 0.938\n",
      "0.064, 1.000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(0.09, grad_fn=<NllLossBackward0>), tensor(0.95))"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model,opt = get_model()\n",
    "fit()\n",
    "loss_func(model(xb), yb), accuracy(model(xb), yb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Multiprocessing DataLoader\n",
    "PyTorch's DataLoader includes considerable code to enable multi-processing. This is crucial for parallelizing per-item batch operations like image loading and augmentation. Because Python's built-in multiprocessing library has limitations with PyTorch tensors, \n",
    "PyTorch offers its own multi-processing solution with the same API but optimized for tensor handling. \n",
    "This is not \"cheating\"; multi-processing is in the Python standard library, and this is API equivalent, so we can use it.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.multiprocessing as mp\n",
    "from fastcore.basics import store_attr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we call square brackets `[]` on a class, it's calling the `__getitem__` function on the object. \n",
    "If we say, give me some items (e.g., 3, 6, 8, and 1),  it's the same as calling `__getitem__` passing in 3, 6, 8, and 1.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
       " tensor([1, 1, 1, 0]))"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[[3,6,8,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
       " tensor([1, 1, 1, 0]))"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.__getitem__([3,6,8,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`map` is the other key piece of \"map-reduce\".\n",
    "`map` takes a sequence and calls a function on every element of that sequence. \n",
    "Given a couple of batches of indices, e.g., `[3,6]` and `[8,1]`, we call` __getitem__`  on each of those batches. \n",
    "So its going to give us the same stuff, but now batched into two batches. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([1, 1]))\n",
      "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([1, 0]))\n"
     ]
    }
   ],
   "source": [
    "for o in map(train_ds.__getitem__, ([3,6],[8,1])): print(o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "multiprocessing (mp) \n",
    "enables parallel execution using `mp.Pool` to manage worker processes. Its `pool.map` function allows parallel application of a function to an iterator's items, analogous to Python's `map`. This parallel processing is key to building a multiprocessing DataLoader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader():\n",
    "    def __init__(self, ds, batchs, n_workers=1, collate_fn=collate): fc.store_attr()\n",
    "    def __iter__(self):\n",
    "        with mp.Pool(self.n_workers) as ex: yield from ex.map(self.ds.__getitem__, iter(self.batchs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`train_dl` below is a multiprocessing DataLoader, with `n_workers=2`.\n",
    "We don't pass in the collate function because we're using the default one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, batchs=train_samp, n_workers=2)\n",
    "it = iter(train_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling `next()` introduces a short latency as two background workers are initialized. This initial overhead may cause the first batch to be slower. However, once the workers are active, the overall throughput for subsequent batches will be significantly improved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 784]), torch.Size([64]))"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb,yb = next(it)\n",
    "xb.shape,yb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### PyTorch DataLoader\n",
    "Instead of a single sampler, Pytorch has two separate classes: `SequentialSampler` and `RandomSampler`,\n",
    "and they've got BatchSampler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "from torch.utils.data import DataLoader, SequentialSampler, RandomSampler, BatchSampler"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training (validation) sampler is a BatchSampler with a RandomSampler (SequentialSampler).\n",
    "We define the samplers, `train_samp` and `valid_samp` passing them in batch sizes `bs`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samp = BatchSampler(RandomSampler(train_ds),     bs, drop_last=False)\n",
    "valid_samp = BatchSampler(SequentialSampler(valid_ds), bs, drop_last=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now pass those samplers to the PyTorch’s DataLoader. \n",
    "It also takes a collate function, works the same as ours with the same API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, batch_sampler=train_samp) #, collate_fn=collate)\n",
    "valid_dl = DataLoader(valid_ds, batch_sampler=valid_samp) #, collate_fn=collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.217, 0.938\n",
      "0.161, 1.000\n",
      "0.012, 1.000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(0.13, grad_fn=<NllLossBackward0>), tensor(0.95))"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model,opt = get_model()\n",
    "fit()\n",
    "loss_func(model(xb), yb), accuracy(model(xb), yb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some shortcuts, e.g., we can just pass the batch size directly to a DataLoader, \n",
    "and it will auto-create the batchsamplers, so we don't have to pass in BatchSampler. \n",
    "Instead we just say `sampler=`, and it will  automatically wrap that in the batchsampler. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch can auto-generate the BatchSampler for us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, bs, sampler=RandomSampler(train_ds)) #, collate_fn=collate)\n",
    "valid_dl = DataLoader(valid_ds, bs, sampler=SequentialSampler(valid_ds)) #, collate_fn=collate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because it's common to create  a RandomSampler or a SequentialSampler for a Dataset, \n",
    "we can just pass in `shuffle=True` or `shuffle=False` to the DataLoader,\n",
    "and PyTorch generates the Sequential/RandomSamplers too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, bs, shuffle=True, drop_last=True, num_workers=2)\n",
    "valid_dl = DataLoader(valid_ds, bs, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.115, 0.984\n",
      "0.174, 0.953\n",
      "0.036, 1.000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(0.04, grad_fn=<NllLossBackward0>), tensor(0.98))"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model,opt = get_model()\n",
    "fit()\n",
    "\n",
    "loss_func(model(xb), yb), accuracy(model(xb), yb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `BatchSampler` provides pre-collated batches of indices, which can be directly used by the DataLoader. \n",
    "Since datasets support retrieving multiple indices at once, we can pass the BatchSampler as a sampler, \n",
    "eliminating the need for manual looping and collation.\n",
    "\n",
    "**TODO**: understand how we can pass a BatchSampler to sampler and what's it doing.\n",
    "For this, lets go back to our non-multi-processing pure Python code to see how that would work. \n",
    "It's a nifty trick to grab multiple things at once and it can save time, make code faster. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
       " tensor([9, 1, 3]))"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[[4,6,7]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...that means that we can skip the `batch_sampler` and `collate_fn` entirely:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, sampler=train_samp)\n",
    "valid_dl = DataLoader(valid_ds, sampler=valid_samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 64, 784]), torch.Size([1, 64]))"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb,yb = next(iter(train_dl))\n",
    "xb.shape,yb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Validation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You **always** should also have a [validation set](http://www.fast.ai/2017/11/13/validation-sets/), in order to identify if you are overfitting.<br>\n",
    "We will calculate and print the validation loss at the end of each epoch.\n",
    "<br>\n",
    "(Note that we always call `model.train()` before training, and `model.eval()` before inference, because these are used by layers such as `nn.BatchNorm2d` and `nn.Dropout` to ensure appropriate behaviour for these different phases.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first part of `fit` is the same code as before.\n",
    "Then we add a `for xb,yb in valid_dl` which goes through the validation set,\n",
    "gets the predictions `pred`, sums up the losses and accuracies,\n",
    "and prints the loss and accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def fit(epochs, model, loss_func, opt, train_dl, valid_dl):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for xb,yb in train_dl:\n",
    "            loss = loss_func(model(xb), yb)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            tot_loss,tot_acc,count = 0.,0.,0\n",
    "            for xb,yb in valid_dl:\n",
    "                pred = model(xb)\n",
    "                n = len(xb)\n",
    "                count += n\n",
    "                tot_loss += loss_func(pred,yb).item()*n\n",
    "                tot_acc  += accuracy (pred,yb).item()*n\n",
    "        print(epoch, tot_loss/count, tot_acc/count)\n",
    "    return tot_loss/count, tot_acc/count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`get_dls()` uses the PyTorch DataLoader to create training and validation loaders, using \n",
    "the training and validation datasets.\n",
    "Notice that for the validation DataLoader, we double the `batch_size`,\n",
    "as it doesn't have to do backpropagation, it should use about half the memory, so we can use a bigger batch size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def get_dls(train_ds, valid_ds, bs, **kwargs):\n",
    "    return (DataLoader(train_ds, batch_size=bs, shuffle=True, **kwargs),\n",
    "            DataLoader(valid_ds, batch_size=bs*2, **kwargs)) # double bs because it does not need to do backprop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, our whole process of obtaining the data loaders and fitting the model can be run in 3 lines of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.1752694676682353 0.9497\n",
      "1 0.1467677358612418 0.9563\n",
      "2 0.20965449111163617 0.9341\n",
      "3 0.11569483358860017 0.9662\n",
      "4 0.18093234625775367 0.9536\n"
     ]
    }
   ],
   "source": [
    "train_dl,valid_dl = get_dls(train_ds, valid_ds, bs)\n",
    "model,opt = get_model()\n",
    "loss,acc = fit(5, model, loss_func, opt, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now it's printing out the loss and accuracy on the **validation** set.\n",
    "(Finally we actually know accuracy on the whole validation set.)\n",
    "**We've now implemented a working training loop, where every line of code is calling stuff that we have implemented.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%pip install -q nbdev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.2'"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nbdev; nbdev.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
